{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import pytorch_lightning as pl\n",
    "from argparse import Namespace\n",
    "from model import DTSModel\n",
    "from datamodules.csvdatamodule import CsvDataModule\n",
    "from datamodules.hivedatamodule import HiveDataModule\n",
    "from datamodules.sqldatamodule import SqlDataModule\n",
    "from datamodules.s3datamodule import S3DataModule\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from dataclasses import dataclass\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    data: dict\n",
    "    model: dict\n",
    "    train:dict\n",
    "        \n",
    "config = Config(\n",
    "    data= {\n",
    "        \"data\": \"csv\",\n",
    "        \"data_params\": {\n",
    "            \"normalize\": 0,\n",
    "            \"dataset\": \"tst\",\n",
    "            \"num_feature\": 5,\n",
    "            \"enc_seq_len\": 30,\n",
    "            \"dec_seq_len\": 5,\n",
    "            \"tgt_seq_len\": 5,\n",
    "            \"batch_size\": 64,\n",
    "            \"train_path\": \"data/AAPL_train.csv\",\n",
    "            \"val_path\": \"data/AAPL_val.csv\",\n",
    "            \"test_path\": \"data/AAPL_test.csv\"\n",
    "        }\n",
    "    },\n",
    "    model= {\n",
    "        \"model_name\": \"tst\",\n",
    "        \"model_params\": {\n",
    "            \"input_size\": 5,\n",
    "            \"enc_seq_len\": 30,\n",
    "            \"dec_seq_len\": 5,\n",
    "            \"out_seq_len\": 5,\n",
    "            \"dim_val\": 512,\n",
    "            \"n_encoder_layers\": 4,\n",
    "            \"n_decoder_layers\": 4,\n",
    "            \"n_heads\": 8,\n",
    "            \"dropout_encoder\": 0.2,\n",
    "            \"dropout_decoder\": 0.2,\n",
    "            \"dropout_pos_enc\": 0.1,\n",
    "            \"dim_feedforward_encoder\": 2048,\n",
    "            \"dim_feedforward_decoder\": 2048,\n",
    "            \"num_predicted_features\": 1,\n",
    "            \"lr\": 1e-4\n",
    "        },\n",
    "        \"loss_fn_type\": \"mse\",\n",
    "        \"loss_params\": {}\n",
    "    },\n",
    "    train=  {\n",
    "        \"accelerator\": \"gpu\",\n",
    "        \"devices\": 1,\n",
    "        \"strategy\": 'ddp',\n",
    "        \"max_epochs\": 50\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42, workers=True)\n",
    "logger = TensorBoardLogger('logs/', name=config.model['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LightningDataModule\n",
    "data_module = CsvDataModule(config.data['data_params'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2959, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data_module.train_data[:,4].reshape(-1, 1)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[[-0.8288, -0.8302, -0.8245, -0.8481, -0.8370],\n",
       "           [-0.8289, -0.8319, -0.8285, -0.8523, -0.7107],\n",
       "           [-0.8353, -0.8350, -0.8327, -0.8552, -0.6602],\n",
       "           ...,\n",
       "           [-0.8268, -0.8270, -0.8222, -0.8438, -0.8314],\n",
       "           [-0.8239, -0.8222, -0.8190, -0.8406, -0.7792],\n",
       "           [-0.8190, -0.8184, -0.8141, -0.8380, -0.7124]],\n",
       "  \n",
       "          [[-0.9246, -0.9273, -0.9237, -0.9369, -0.6629],\n",
       "           [-0.9268, -0.9283, -0.9251, -0.9376, -0.7026],\n",
       "           [-0.9255, -0.9258, -0.9236, -0.9356, -0.5890],\n",
       "           ...,\n",
       "           [-0.9081, -0.9081, -0.9055, -0.9190, -0.4118],\n",
       "           [-0.9062, -0.9056, -0.9035, -0.9185, -0.1930],\n",
       "           [-0.9031, -0.9052, -0.9010, -0.9169, -0.3418]],\n",
       "  \n",
       "          [[-0.8521, -0.8508, -0.8480, -0.8690, -0.6821],\n",
       "           [-0.8474, -0.8502, -0.8454, -0.8688, -0.7630],\n",
       "           [-0.8472, -0.8492, -0.8432, -0.8678, -0.8290],\n",
       "           ...,\n",
       "           [-0.8160, -0.8178, -0.8120, -0.8410, -0.6227],\n",
       "           [-0.8145, -0.8174, -0.8106, -0.8411, -0.7553],\n",
       "           [-0.8159, -0.8184, -0.8115, -0.8416, -0.8460]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-0.9181, -0.9188, -0.9161, -0.9289, -0.5545],\n",
       "           [-0.9186, -0.9212, -0.9195, -0.9325, -0.2609],\n",
       "           [-0.9239, -0.9240, -0.9239, -0.9337, -0.0873],\n",
       "           ...,\n",
       "           [-0.9283, -0.9278, -0.9275, -0.9363, -0.2036],\n",
       "           [-0.9265, -0.9262, -0.9246, -0.9349, -0.4549],\n",
       "           [-0.9223, -0.9234, -0.9210, -0.9345, -0.3925]],\n",
       "  \n",
       "          [[-0.4937, -0.4956, -0.4829, -0.5055, -0.8462],\n",
       "           [-0.4995, -0.4972, -0.4883, -0.5103, -0.8561],\n",
       "           [-0.4928, -0.4895, -0.4786, -0.5010, -0.8897],\n",
       "           ...,\n",
       "           [-0.4327, -0.4311, -0.4201, -0.4438, -0.8924],\n",
       "           [-0.4254, -0.4300, -0.4252, -0.4515, -0.9029],\n",
       "           [-0.4376, -0.4354, -0.4265, -0.4471, -0.8691]],\n",
       "  \n",
       "          [[ 0.5975,  0.6021,  0.5918,  0.5794, -0.8422],\n",
       "           [ 0.5684,  0.5826,  0.5856,  0.5780, -0.9156],\n",
       "           [ 0.5766,  0.5946,  0.6073,  0.6031, -0.9323],\n",
       "           ...,\n",
       "           [ 0.7984,  0.8093,  0.7954,  0.7762, -0.9241],\n",
       "           [ 0.7383,  0.7785,  0.7824,  0.7981, -0.9609],\n",
       "           [ 0.7671,  0.7620,  0.7885,  0.7856, -0.9548]]], dtype=torch.float64),\n",
       "  tensor([[[-0.8239, -0.8268, -0.8214, -0.8450, -0.7995],\n",
       "           [-0.8268, -0.8270, -0.8222, -0.8438, -0.8314],\n",
       "           [-0.8239, -0.8222, -0.8190, -0.8406, -0.7792],\n",
       "           [-0.8190, -0.8184, -0.8141, -0.8380, -0.7124],\n",
       "           [-0.8163, -0.8183, -0.8140, -0.8383, -0.6976]],\n",
       "  \n",
       "          [[-0.9075, -0.9085, -0.9052, -0.9209, -0.3216],\n",
       "           [-0.9081, -0.9081, -0.9055, -0.9190, -0.4118],\n",
       "           [-0.9062, -0.9056, -0.9035, -0.9185, -0.1930],\n",
       "           [-0.9031, -0.9052, -0.9010, -0.9169, -0.3418],\n",
       "           [-0.9021, -0.9046, -0.9007, -0.9175, -0.5234]],\n",
       "  \n",
       "          [[-0.8213, -0.8201, -0.8162, -0.8426, -0.6362],\n",
       "           [-0.8160, -0.8178, -0.8120, -0.8410, -0.6227],\n",
       "           [-0.8145, -0.8174, -0.8106, -0.8411, -0.7553],\n",
       "           [-0.8159, -0.8184, -0.8115, -0.8416, -0.8460],\n",
       "           [-0.8151, -0.8169, -0.8106, -0.8395, -0.7372]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-0.9247, -0.9273, -0.9273, -0.9396, -0.1183],\n",
       "           [-0.9283, -0.9278, -0.9275, -0.9363, -0.2036],\n",
       "           [-0.9265, -0.9262, -0.9246, -0.9349, -0.4549],\n",
       "           [-0.9223, -0.9234, -0.9210, -0.9345, -0.3925],\n",
       "           [-0.9225, -0.9231, -0.9202, -0.9320, -0.4120]],\n",
       "  \n",
       "          [[-0.4477, -0.4369, -0.4325, -0.4521, -0.8547],\n",
       "           [-0.4327, -0.4311, -0.4201, -0.4438, -0.8924],\n",
       "           [-0.4254, -0.4300, -0.4252, -0.4515, -0.9029],\n",
       "           [-0.4376, -0.4354, -0.4265, -0.4471, -0.8691],\n",
       "           [-0.4100, -0.4140, -0.4041, -0.4313, -0.7906]],\n",
       "  \n",
       "          [[ 0.7960,  0.7949,  0.8275,  0.8152, -0.9599],\n",
       "           [ 0.7984,  0.8093,  0.7954,  0.7762, -0.9241],\n",
       "           [ 0.7383,  0.7785,  0.7824,  0.7981, -0.9609],\n",
       "           [ 0.7671,  0.7620,  0.7885,  0.7856, -0.9548],\n",
       "           [ 0.7696,  0.7707,  0.8037,  0.7762, -0.9632]]], dtype=torch.float64)],\n",
       " tensor([[-0.8438, -0.8406, -0.8380, -0.8383, -0.8364],\n",
       "         [-0.9190, -0.9185, -0.9169, -0.9175, -0.9194],\n",
       "         [-0.8410, -0.8411, -0.8416, -0.8395, -0.8375],\n",
       "         [ 0.1877,  0.1950,  0.2344,  0.2675,  0.2042],\n",
       "         [ 0.7981,  0.7856,  0.7762,  0.8677,  0.8667],\n",
       "         [-0.0780, -0.0609, -0.0687, -0.0555, -0.0577],\n",
       "         [-0.4767, -0.4746, -0.4772, -0.4908, -0.4898],\n",
       "         [-0.6392, -0.6348, -0.6384, -0.6326, -0.6277],\n",
       "         [-0.7162, -0.7138, -0.7133, -0.7141, -0.7007],\n",
       "         [-0.5024, -0.5050, -0.5003, -0.4925, -0.4940],\n",
       "         [-0.7661, -0.7671, -0.7676, -0.7688, -0.7653],\n",
       "         [-0.7134, -0.7211, -0.7162, -0.7138, -0.7133],\n",
       "         [-0.8727, -0.8719, -0.8704, -0.8713, -0.8722],\n",
       "         [-0.9314, -0.9289, -0.9325, -0.9337, -0.9382],\n",
       "         [-0.9347, -0.9345, -0.9354, -0.9373, -0.9422],\n",
       "         [-0.5570, -0.5554, -0.5552, -0.5559, -0.5507],\n",
       "         [-0.6620, -0.6694, -0.6705, -0.6770, -0.6821],\n",
       "         [-0.6505, -0.6505, -0.6506, -0.6468, -0.6535],\n",
       "         [-0.8292, -0.8269, -0.8325, -0.8329, -0.8331],\n",
       "         [-0.4223, -0.4153, -0.4107, -0.4103, -0.4083],\n",
       "         [-0.9309, -0.9311, -0.9279, -0.9314, -0.9289],\n",
       "         [ 0.1343,  0.1440,  0.1580,  0.1416,  0.1472],\n",
       "         [ 0.3919,  0.3889,  0.4193,  0.3990,  0.4031],\n",
       "         [-0.2548, -0.2544, -0.2483, -0.2570, -0.2455],\n",
       "         [-0.6439, -0.6412, -0.6333, -0.6235, -0.6181],\n",
       "         [-0.6696, -0.6692, -0.6786, -0.6753, -0.6767],\n",
       "         [-0.6038, -0.6038, -0.5992, -0.5953, -0.6053],\n",
       "         [-0.4746, -0.4772, -0.4908, -0.4898, -0.4901],\n",
       "         [-0.6230, -0.6204, -0.6122, -0.6167, -0.6183],\n",
       "         [ 0.1580,  0.1416,  0.1472,  0.1400,  0.1683],\n",
       "         [-0.6145, -0.6200, -0.6155, -0.6173, -0.6286],\n",
       "         [-0.7653, -0.7648, -0.7647, -0.7672, -0.7630],\n",
       "         [-0.6360, -0.6388, -0.6379, -0.6353, -0.6371],\n",
       "         [-0.4149, -0.4217, -0.4224, -0.4200, -0.4200],\n",
       "         [-0.9065, -0.9064, -0.9056, -0.9082, -0.9058],\n",
       "         [-0.4433, -0.4623, -0.4772, -0.4995, -0.5138],\n",
       "         [-0.5376, -0.5383, -0.5393, -0.5391, -0.5353],\n",
       "         [-0.7061, -0.7144, -0.7160, -0.7156, -0.7173],\n",
       "         [-0.6711, -0.6713, -0.6689, -0.6790, -0.6874],\n",
       "         [ 0.1114,  0.1064,  0.1209,  0.1339,  0.1259],\n",
       "         [-0.7587, -0.7591, -0.7565, -0.7511, -0.7432],\n",
       "         [-0.6291, -0.6184, -0.6250, -0.6256, -0.6220],\n",
       "         [-0.4134, -0.4255, -0.4247, -0.4283, -0.4230],\n",
       "         [-0.8150, -0.8166, -0.8152, -0.8114, -0.8169],\n",
       "         [-0.6269, -0.6282, -0.6303, -0.6340, -0.6439],\n",
       "         [-0.8867, -0.8833, -0.8792, -0.8778, -0.8732],\n",
       "         [-0.6636, -0.6682, -0.6642, -0.6727, -0.6722],\n",
       "         [-0.2145, -0.2043, -0.2192, -0.2327, -0.2346],\n",
       "         [-0.6184, -0.6250, -0.6256, -0.6220, -0.6150],\n",
       "         [-0.7527, -0.7583, -0.7688, -0.7576, -0.7672],\n",
       "         [-0.8502, -0.8489, -0.8488, -0.8481, -0.8514],\n",
       "         [ 0.1550,  0.1426,  0.1155,  0.0601,  0.0224],\n",
       "         [-0.8031, -0.7995, -0.8010, -0.8040, -0.8036],\n",
       "         [-0.0446, -0.0420, -0.0283, -0.0107, -0.0087],\n",
       "         [-0.9014, -0.9011, -0.8984, -0.9010, -0.9017],\n",
       "         [-0.6765, -0.6807, -0.6740, -0.6789, -0.6861],\n",
       "         [-0.6575, -0.6536, -0.6471, -0.6494, -0.6427],\n",
       "         [-0.6612, -0.6599, -0.6617, -0.6792, -0.6632],\n",
       "         [-0.6657, -0.6651, -0.6705, -0.6648, -0.6677],\n",
       "         [-0.7964, -0.7965, -0.7977, -0.7957, -0.7927],\n",
       "         [-0.8222, -0.8224, -0.8202, -0.8234, -0.8207],\n",
       "         [-0.9363, -0.9349, -0.9345, -0.9320, -0.9285],\n",
       "         [-0.4438, -0.4515, -0.4471, -0.4313, -0.4250],\n",
       "         [ 0.7762,  0.7981,  0.7856,  0.7762,  0.8677]], dtype=torch.float64)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_module.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DTSModel(\n",
       "  (model): TSTModel(\n",
       "    (encoder_input_layer): Linear(in_features=5, out_features=512, bias=True)\n",
       "    (decoder_input_layer): Linear(in_features=5, out_features=512, bias=True)\n",
       "    (linear_mapping): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (positional_encoding_layer): PositionalEncoder(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "          (dropout3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "          (dropout3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "          (dropout3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "          (dropout3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (loss_fn): MSE()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create LightningModule\n",
    "device = torch.device('cuda') if config.train['accelerator']=='gpu' else torch.device('cpu')\n",
    "model = DTSModel(config.model, device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/hd1/anaconda3/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /hd1/dl/deep_time_series_framework/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type     | Params\n",
      "-------------------------------------\n",
      "0 | model   | TSTModel | 29.4 M\n",
      "1 | loss_fn | MSE      | 0     \n",
      "-------------------------------------\n",
      "29.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "29.4 M    Total params\n",
      "117.729   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hd1/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (46) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb1b7260716432ab1211bc3dff47a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Callback to save the model checkpoint\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_loss',\n",
    "        dirpath='./checkpoints/',\n",
    "        filename='model-{epoch:02d}-{val_loss:.2f}',\n",
    "        save_top_k=3,\n",
    "        mode='min',\n",
    "        save_last=True,\n",
    "        every_n_epochs=1,  # Save checkpoint every epoch\n",
    "    )\n",
    "\n",
    "# Create Trainer\n",
    "trainer = pl.Trainer(\n",
    "        accelerator=config.train['accelerator'],\n",
    "        devices=config.train['devices'],\n",
    "        #strategy=config.train['strategy'],\n",
    "        max_epochs=config.train['max_epochs'],\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='val_loss',patience=5,verbose=False, mode='min'),\n",
    "            LearningRateMonitor(logging_interval='step'),\n",
    "            checkpoint_callback\n",
    "        ],\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hd1/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:124: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "  rank_zero_warn(\n",
      "Restoring states from the checkpoint path at /hd1/dl/deep_time_series_framework/checkpoints/model-epoch=26-val_loss=0.01.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /hd1/dl/deep_time_series_framework/checkpoints/model-epoch=26-val_loss=0.01.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092fc407c15f41c694463e933f91c9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss          0.015542013570666313\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.test(datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.015542013570666313}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_loader = data_module.val_dataloader()\n",
    "predictions = []\n",
    "model.to(device)\n",
    "for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
    "    if batch_idx !=0: continue\n",
    "    \n",
    "    outputs = model((inputs[0].to(device),inputs[1].to(device)))\n",
    "    if config.data['data_params']['normalize']:\n",
    "        outputs = data_module.target_denormalize(outputs.detach().cpu().numpy().squeeze()[:,-1])\n",
    "        labels = data_module.target_denormalize(labels.detach().cpu().numpy().squeeze()[:,-1])\n",
    "    else:\n",
    "        outputs = outputs.detach().cpu().numpy().squeeze()[:,-1]\n",
    "        labels = labels.detach().cpu().numpy().squeeze()[:,-1]\n",
    "\n",
    "    predictions.append(list(zip(labels, outputs)))\n",
    "#predictions = np.concatenate(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(128.3253173828125, 125.42912),\n",
       "  (124.50135803222656, 138.39554),\n",
       "  (124.3630142211914, 132.16508),\n",
       "  (123.8590850830078, 123.34227),\n",
       "  (119.55094909667967, 123.2675),\n",
       "  (119.81771850585938, 118.131615),\n",
       "  (126.2700653076172, 114.279945),\n",
       "  (123.63182067871094, 127.98467),\n",
       "  (120.60820770263672, 122.024345),\n",
       "  (118.70115661621094, 124.391754),\n",
       "  (119.97582244873048, 117.91181),\n",
       "  (114.97601318359376, 118.30691),\n",
       "  (119.64974212646484, 119.624825),\n",
       "  (118.55294799804688, 123.337),\n",
       "  (120.5093994140625, 123.46673),\n",
       "  (119.59046173095705, 113.30608),\n",
       "  (122.51525115966795, 109.20789),\n",
       "  (124.0764617919922, 130.36186),\n",
       "  (123.2761001586914, 121.60758),\n",
       "  (119.09642028808594, 121.1298),\n",
       "  (118.56283569335938, 123.4035),\n",
       "  (121.92239379882812, 118.10034),\n",
       "  (121.08251190185547, 120.71583),\n",
       "  (118.66165161132812, 114.06972),\n",
       "  (119.15569305419922, 115.39009),\n",
       "  (119.76832580566406, 123.80464),\n",
       "  (119.9461898803711, 129.58725),\n",
       "  (118.47390747070312, 116.17007),\n",
       "  (120.6971435546875, 106.70613),\n",
       "  (121.53704071044922, 117.406525),\n",
       "  (124.4025421142578, 125.33478),\n",
       "  (124.70885467529295, 111.52374),\n",
       "  (126.37875366210938, 112.64972),\n",
       "  (128.8094940185547, 122.6807),\n",
       "  (131.4180908203125, 129.05748),\n",
       "  (129.6790313720703, 122.68923),\n",
       "  (132.83108520507812, 124.40994),\n",
       "  (130.45965576171875, 123.756096),\n",
       "  (132.90023803710938, 130.38666),\n",
       "  (132.56427001953125, 134.7281),\n",
       "  (133.23619079589844, 136.4676),\n",
       "  (131.5267791748047, 130.78413),\n",
       "  (131.9121551513672, 138.51538),\n",
       "  (130.37069702148438, 139.11275),\n",
       "  (132.72241210937503, 127.70181),\n",
       "  (133.1176300048828, 134.72182),\n",
       "  (132.7915496826172, 128.89539),\n",
       "  (131.99118041992188, 124.98284),\n",
       "  (131.89239501953125, 126.543274),\n",
       "  (129.89642333984375, 127.63034),\n",
       "  (130.96356201171875, 130.14676),\n",
       "  (126.329345703125, 125.90163),\n",
       "  (126.57637786865234, 117.32586),\n",
       "  (128.19686889648438, 125.7566),\n",
       "  (128.87982177734375, 131.2628),\n",
       "  (125.55414581298828, 121.361465),\n",
       "  (124.62374877929688, 131.34793),\n",
       "  (121.5158233642578, 128.3918),\n",
       "  (123.69335174560548, 119.704994),\n",
       "  (126.14800262451172, 114.17196),\n",
       "  (124.98006439208984, 119.52451),\n",
       "  (123.57457733154295, 135.88828),\n",
       "  (123.4162139892578, 124.894844),\n",
       "  (126.00944519042967, 121.971375)]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
